{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147d4825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T11:17:16.979544Z",
     "start_time": "2022-08-11T11:17:16.971125Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")\n",
    "from torch.nn import LayerNorm, Linear, Dropout, Softmax\n",
    "from einops import rearrange, repeat\n",
    "import copy\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from pathlib import Path\n",
    "import re\n",
    "import torch.backends.cudnn as cudnn\n",
    "import record\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "from operator import truediv\n",
    "import math\n",
    "from PIL import Image\n",
    "import time\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.nn.parameter import Parameter\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import loadmat as loadmat\n",
    "from scipy import io\n",
    "import torch.utils.data as dataf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import einsum\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147bde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T15:57:46.340980Z",
     "start_time": "2022-02-03T15:57:46.331571Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a158b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T11:17:22.621087Z",
     "start_time": "2022-08-11T11:17:22.455132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 8, 136, 11, 11]      --\n",
      "|    └─Conv3d: 2-1                            [-1, 8, 136, 11, 11]      656\n",
      "|    └─BatchNorm3d: 2-2                       [-1, 8, 136, 11, 11]      16\n",
      "|    └─ReLU: 2-3                              [-1, 8, 136, 11, 11]      --\n",
      "├─Sequential: 1-2                             [-1, 64, 11, 11]          --\n",
      "|    └─HetConv: 2-4                           [-1, 64, 11, 11]          --\n",
      "|    |    └─Conv2d: 3-1                       [-1, 64, 11, 11]          39,232\n",
      "|    |    └─Conv2d: 3-2                       [-1, 64, 11, 11]          69,696\n",
      "|    └─BatchNorm2d: 2-5                       [-1, 64, 11, 11]          128\n",
      "|    └─ReLU: 2-6                              [-1, 64, 11, 11]          --\n",
      "├─Sequential: 1-3                             [-1, 64, 11, 11]          --\n",
      "|    └─Conv2d: 2-7                            [-1, 64, 11, 11]          640\n",
      "|    └─BatchNorm2d: 2-8                       [-1, 64, 11, 11]          128\n",
      "|    └─GELU: 2-9                              [-1, 64, 11, 11]          --\n",
      "├─Dropout: 1-4                                [-1, 5, 64]               --\n",
      "├─TransformerEncoder: 1-5                     [-1, 64]                  --\n",
      "|    └─LayerNorm: 2-10                        [-1, 5, 64]               128\n",
      "|    |    └─Block: 3-3                        [-1, 5, 64]               --\n",
      "|    |    |    └─LayerNorm: 4-1               [-1, 5, 64]               128\n",
      "|    |    |    └─MCrossAttention: 4-2         [-1, 1, 64]               --\n",
      "|    |    |    |    └─Linear: 5-1             [-1, 1, 8, 64]            512\n",
      "|    |    |    |    └─Linear: 5-2             [-1, 5, 8, 64]            512\n",
      "|    |    |    |    └─Linear: 5-3             [-1, 5, 8, 64]            512\n",
      "|    |    |    |    └─Linear: 5-4             [-1, 1, 64]               32,832\n",
      "|    |    |    |    └─Dropout: 5-5            [-1, 1, 64]               --\n",
      "|    |    |    └─LayerNorm: 4-3               [-1, 5, 64]               128\n",
      "|    |    |    └─Mlp: 4-4                     [-1, 5, 64]               --\n",
      "|    |    |    |    └─Linear: 5-6             [-1, 5, 512]              33,280\n",
      "|    |    |    |    └─GELU: 5-7               [-1, 5, 512]              --\n",
      "|    |    |    |    └─Dropout: 5-8            [-1, 5, 512]              --\n",
      "|    |    |    |    └─Linear: 5-9             [-1, 5, 64]               32,832\n",
      "|    |    |    |    └─Dropout: 5-10           [-1, 5, 64]               --\n",
      "|    |    └─Block: 3-4                        [-1, 5, 64]               --\n",
      "|    |    |    └─LayerNorm: 4-5               [-1, 5, 64]               128\n",
      "|    |    |    └─MCrossAttention: 4-6         [-1, 1, 64]               --\n",
      "|    |    |    |    └─Linear: 5-11            [-1, 1, 8, 64]            512\n",
      "|    |    |    |    └─Linear: 5-12            [-1, 5, 8, 64]            512\n",
      "|    |    |    |    └─Linear: 5-13            [-1, 5, 8, 64]            512\n",
      "|    |    |    |    └─Linear: 5-14            [-1, 1, 64]               32,832\n",
      "|    |    |    |    └─Dropout: 5-15           [-1, 1, 64]               --\n",
      "|    |    |    └─LayerNorm: 4-7               [-1, 5, 64]               128\n",
      "|    |    |    └─Mlp: 4-8                     [-1, 5, 64]               --\n",
      "|    |    |    |    └─Linear: 5-16            [-1, 5, 512]              33,280\n",
      "|    |    |    |    └─GELU: 5-17              [-1, 5, 512]              --\n",
      "|    |    |    |    └─Dropout: 5-18           [-1, 5, 512]              --\n",
      "|    |    |    |    └─Linear: 5-19            [-1, 5, 64]               32,832\n",
      "|    |    |    |    └─Dropout: 5-20           [-1, 5, 64]               --\n",
      "├─Linear: 1-6                                 [-1, 15]                  975\n",
      "===============================================================================================\n",
      "Total params: 313,071\n",
      "Trainable params: 313,071\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 2.45\n",
      "Params size (MB): 1.19\n",
      "Estimated Total Size (MB): 3.71\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-----------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Sequential: 1-1                             [-1, 8, 136, 11, 11]      --\n",
       "|    └─Conv3d: 2-1                            [-1, 8, 136, 11, 11]      656\n",
       "|    └─BatchNorm3d: 2-2                       [-1, 8, 136, 11, 11]      16\n",
       "|    └─ReLU: 2-3                              [-1, 8, 136, 11, 11]      --\n",
       "├─Sequential: 1-2                             [-1, 64, 11, 11]          --\n",
       "|    └─HetConv: 2-4                           [-1, 64, 11, 11]          --\n",
       "|    |    └─Conv2d: 3-1                       [-1, 64, 11, 11]          39,232\n",
       "|    |    └─Conv2d: 3-2                       [-1, 64, 11, 11]          69,696\n",
       "|    └─BatchNorm2d: 2-5                       [-1, 64, 11, 11]          128\n",
       "|    └─ReLU: 2-6                              [-1, 64, 11, 11]          --\n",
       "├─Sequential: 1-3                             [-1, 64, 11, 11]          --\n",
       "|    └─Conv2d: 2-7                            [-1, 64, 11, 11]          640\n",
       "|    └─BatchNorm2d: 2-8                       [-1, 64, 11, 11]          128\n",
       "|    └─GELU: 2-9                              [-1, 64, 11, 11]          --\n",
       "├─Dropout: 1-4                                [-1, 5, 64]               --\n",
       "├─TransformerEncoder: 1-5                     [-1, 64]                  --\n",
       "|    └─LayerNorm: 2-10                        [-1, 5, 64]               128\n",
       "|    |    └─Block: 3-3                        [-1, 5, 64]               --\n",
       "|    |    |    └─LayerNorm: 4-1               [-1, 5, 64]               128\n",
       "|    |    |    └─MCrossAttention: 4-2         [-1, 1, 64]               --\n",
       "|    |    |    |    └─Linear: 5-1             [-1, 1, 8, 64]            512\n",
       "|    |    |    |    └─Linear: 5-2             [-1, 5, 8, 64]            512\n",
       "|    |    |    |    └─Linear: 5-3             [-1, 5, 8, 64]            512\n",
       "|    |    |    |    └─Linear: 5-4             [-1, 1, 64]               32,832\n",
       "|    |    |    |    └─Dropout: 5-5            [-1, 1, 64]               --\n",
       "|    |    |    └─LayerNorm: 4-3               [-1, 5, 64]               128\n",
       "|    |    |    └─Mlp: 4-4                     [-1, 5, 64]               --\n",
       "|    |    |    |    └─Linear: 5-6             [-1, 5, 512]              33,280\n",
       "|    |    |    |    └─GELU: 5-7               [-1, 5, 512]              --\n",
       "|    |    |    |    └─Dropout: 5-8            [-1, 5, 512]              --\n",
       "|    |    |    |    └─Linear: 5-9             [-1, 5, 64]               32,832\n",
       "|    |    |    |    └─Dropout: 5-10           [-1, 5, 64]               --\n",
       "|    |    └─Block: 3-4                        [-1, 5, 64]               --\n",
       "|    |    |    └─LayerNorm: 4-5               [-1, 5, 64]               128\n",
       "|    |    |    └─MCrossAttention: 4-6         [-1, 1, 64]               --\n",
       "|    |    |    |    └─Linear: 5-11            [-1, 1, 8, 64]            512\n",
       "|    |    |    |    └─Linear: 5-12            [-1, 5, 8, 64]            512\n",
       "|    |    |    |    └─Linear: 5-13            [-1, 5, 8, 64]            512\n",
       "|    |    |    |    └─Linear: 5-14            [-1, 1, 64]               32,832\n",
       "|    |    |    |    └─Dropout: 5-15           [-1, 1, 64]               --\n",
       "|    |    |    └─LayerNorm: 4-7               [-1, 5, 64]               128\n",
       "|    |    |    └─Mlp: 4-8                     [-1, 5, 64]               --\n",
       "|    |    |    |    └─Linear: 5-16            [-1, 5, 512]              33,280\n",
       "|    |    |    |    └─GELU: 5-17              [-1, 5, 512]              --\n",
       "|    |    |    |    └─Dropout: 5-18           [-1, 5, 512]              --\n",
       "|    |    |    |    └─Linear: 5-19            [-1, 5, 64]               32,832\n",
       "|    |    |    |    └─Dropout: 5-20           [-1, 5, 64]               --\n",
       "├─Linear: 1-6                                 [-1, 15]                  975\n",
       "===============================================================================================\n",
       "Total params: 313,071\n",
       "Trainable params: 313,071\n",
       "Non-trainable params: 0\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 2.45\n",
       "Params size (MB): 1.19\n",
       "Estimated Total Size (MB): 3.71\n",
       "-----------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MFT WITH CHANNEL TOKENIZATION\n",
    "\n",
    "from torch.nn import LayerNorm,Linear,Dropout,Softmax\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def INF(B,H,W):\n",
    "     return -torch.diag(torch.tensor(float(\"inf\")).cuda().repeat(H),0).unsqueeze(0).repeat(B*W,1,1)\n",
    "\n",
    "     \n",
    "class HetConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,padding = None, bias = None,p = 64, g = 64):\n",
    "        super(HetConv, self).__init__()\n",
    "        # Groupwise Convolution\n",
    "        self.gwc = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,groups=g,padding = kernel_size//3, stride = stride)\n",
    "        # Pointwise Convolution\n",
    "        self.pwc = nn.Conv2d(in_channels, out_channels, kernel_size=1,groups=p, stride = stride)\n",
    "    def forward(self, x):\n",
    "        return self.gwc(x) + self.pwc(x)   \n",
    "\n",
    "class MCrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0.1, proj_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "        self.wk = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "        self.wv = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "#         self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim * num_heads, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        q = self.wq(x[:, 0:1, ...].reshape(B, 1, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  # B1C -> B1H(C/H) -> BH1(C/H)\n",
    "        k = self.wk(x.reshape(B, N, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "        v = self.wv(x.reshape(B, N, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "        attn = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "#         attn = (q @ k.transpose(-2, -1)) * self.scale  # BH1(C/H) @ BH(C/H)N -> BH1N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "#         attn = self.attn_drop(attn)\n",
    "        x = torch.einsum('bhij,bhjd->bhid', attn, v).transpose(1, 2)\n",
    "#         x = (attn @ v).transpose(1, 2)\n",
    "        x = x.reshape(B, 1, C * self.num_heads)   # (BH1N @ BHN(C/H)) -> BH1(C/H) -> B1H(C/H) -> B1C\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.fc1 = Linear(dim, 512)\n",
    "        self.fc2 = Linear(512, dim)\n",
    "        self.act_fn = nn.GELU()\n",
    "        self.dropout = Dropout(0.1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
    "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Block, self).__init__()\n",
    "        self.hidden_size = dim\n",
    "        self.attention_norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.ffn_norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.ffn = Mlp(dim)\n",
    "#         self.attn = Attention(dim = 64)\n",
    "        self.attn = MCrossAttention(dim = dim)\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        x = self.attention_norm(x)\n",
    "        x= self.attn(x)\n",
    "        x = x + h\n",
    "\n",
    "        h = x\n",
    "        x = self.ffn_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = x + h\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads= 8, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0.1, attn_drop=0.1,\n",
    "                 drop_path=0.1, act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=False):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.encoder_norm = LayerNorm(dim, eps=1e-6)\n",
    "        for _ in range(2):\n",
    "            layer = Block(dim)\n",
    "            self.layer.append(copy.deepcopy(layer))\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer_block in self.layer:\n",
    "            x= layer_block(x)\n",
    "            \n",
    "        encoded = self.encoder_norm(x)\n",
    "       \n",
    "        \n",
    "\n",
    "        return encoded[:,0]\n",
    "\n",
    "\n",
    "class MFT(nn.Module):\n",
    "    def __init__(self, FM, NC, NCLidar, Classes, HSIOnly):\n",
    "        super(MFT, self).__init__()\n",
    "        self.HSIOnly = HSIOnly\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, (9, 3, 3), padding=(0,1,1), stride = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv6 = nn.Sequential(\n",
    "            HetConv(8 * (NC - 8), FM*4,\n",
    "                p = 1,\n",
    "                g = (FM*4)//4 if (8 * (NC - 8))%FM == 0 else (FM*4)//8,\n",
    "                   ),\n",
    "            nn.BatchNorm2d(FM*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.last_BandSize = NC//2//2//2\n",
    "        \n",
    "        self.lidarConv = nn.Sequential(\n",
    "                        nn.Conv2d(NCLidar,64,3,1,1),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.GELU()\n",
    "                        )\n",
    "        self.ca = TransformerEncoder(FM*4)\n",
    "        self.out3 = nn.Linear(FM*4 , Classes)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(1, 4 + 1, FM*4))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        torch.nn.init.xavier_uniform_(self.out3.weight)\n",
    "        torch.nn.init.normal_(self.out3.bias, std=1e-6)\n",
    "        self.token_wA = nn.Parameter(torch.empty(1, 4, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wA)\n",
    "        self.token_wV = nn.Parameter(torch.empty(1, 64, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wV)\n",
    "        \n",
    "        self.token_wA_L = nn.Parameter(torch.empty(1, 1, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wA_L)\n",
    "        self.token_wV_L = nn.Parameter(torch.empty(1, 64, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wV_L)\n",
    "                \n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = x1.reshape(x1.shape[0],-1,patchsize,patchsize)\n",
    "        x1 = x1.unsqueeze(1)\n",
    "        x2 = x2.reshape(x2.shape[0],-1,patchsize,patchsize)\n",
    "        x1 = self.conv5(x1)\n",
    "        x1 = x1.reshape(x1.shape[0],-1,patchsize,patchsize)\n",
    "        \n",
    "        x1 = self.conv6(x1)\n",
    "        x2 = self.lidarConv(x2)\n",
    "        x2 = x2.reshape(x2.shape[0],-1,patchsize**2)\n",
    "        x2 = x2.transpose(-1, -2)\n",
    "        wa_L = self.token_wA_L.expand(x1.shape[0],-1,-1)\n",
    "        wa_L = rearrange(wa_L, 'b h w -> b w h')  # Transpose\n",
    "        A_L = torch.einsum('bij,bjk->bik', x2, wa_L)\n",
    "        A_L = rearrange(A_L, 'b h w -> b w h')  # Transpose\n",
    "        A_L = A_L.softmax(dim=-1)\n",
    "        wv_L = self.token_wV_L.expand(x2.shape[0],-1,-1)\n",
    "        VV_L = torch.einsum('bij,bjk->bik', x2, wv_L)\n",
    "        x2 = torch.einsum('bij,bjk->bik', A_L, VV_L)\n",
    "        x1 = x1.flatten(2)\n",
    "        \n",
    "        x1 = x1.transpose(-1, -2)\n",
    "        wa = self.token_wA.expand(x1.shape[0],-1,-1)\n",
    "        wa = rearrange(wa, 'b h w -> b w h')  # Transpose\n",
    "        A = torch.einsum('bij,bjk->bik', x1, wa)\n",
    "        A = rearrange(A, 'b h w -> b w h')  # Transpose\n",
    "        A = A.softmax(dim=-1)\n",
    "        wv = self.token_wV.expand(x1.shape[0],-1,-1)\n",
    "        VV = torch.einsum('bij,bjk->bik', x1, wv)\n",
    "        T = torch.einsum('bij,bjk->bik', A, VV)\n",
    "        x = torch.cat((x2, T), dim = 1) #[b,n+1,dim]\n",
    "        embeddings = x + self.position_embeddings\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        x = self.ca(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        out3 = self.out3(x)\n",
    "        return out3\n",
    "  \n",
    "\n",
    "\n",
    "batchsize = 64\n",
    "patchsize = 11\n",
    "model = MFT(16, 144,1, 15, False)\n",
    "summary(model, [(144,121),(1,121)],device = 'cpu',depth = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db47558e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T11:18:10.978783Z",
     "start_time": "2022-08-11T11:18:01.894932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Training for  Trento  ---------------------------------------------\n",
      "HSI Train data shape =  torch.Size([819, 63, 121])\n",
      "LIDAR Train data shape =  torch.Size([819, 1, 121])\n",
      "Train label shape =  torch.Size([819])\n",
      "HSI Test data shape =  torch.Size([29395, 63, 121])\n",
      "LIDAR Test data shape =  torch.Size([29395, 1, 121])\n",
      "Test label shape =  torch.Size([29395])\n",
      "Number of Classes =  6\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 8, 55, 11, 11]       --\n",
      "|    └─Conv3d: 2-1                            [-1, 8, 55, 11, 11]       656\n",
      "|    └─BatchNorm3d: 2-2                       [-1, 8, 55, 11, 11]       16\n",
      "|    └─ReLU: 2-3                              [-1, 8, 55, 11, 11]       --\n",
      "├─Sequential: 1-2                             [-1, 64, 11, 11]          --\n",
      "|    └─HetConv: 2-4                           [-1, 64, 11, 11]          --\n",
      "|    |    └─Conv2d: 3-1                       [-1, 64, 11, 11]          31,744\n",
      "|    |    └─Conv2d: 3-2                       [-1, 64, 11, 11]          28,224\n",
      "|    └─BatchNorm2d: 2-5                       [-1, 64, 11, 11]          128\n",
      "|    └─ReLU: 2-6                              [-1, 64, 11, 11]          --\n",
      "├─Sequential: 1-3                             [-1, 64, 11, 11]          --\n",
      "|    └─Conv2d: 2-7                            [-1, 64, 11, 11]          640\n",
      "|    └─BatchNorm2d: 2-8                       [-1, 64, 11, 11]          128\n",
      "|    └─GELU: 2-9                              [-1, 64, 11, 11]          --\n",
      "├─Dropout: 1-4                                [-1, 5, 64]               --\n",
      "├─TransformerEncoder: 1-5                     [-1, 64]                  --\n",
      "|    └─LayerNorm: 2-10                        [-1, 5, 64]               128\n",
      "|    |    └─Block: 3-3                        [-1, 5, 64]               100,736\n",
      "|    |    └─Block: 3-4                        [-1, 5, 64]               100,736\n",
      "├─Linear: 1-6                                 [-1, 6]                   390\n",
      "===============================================================================================\n",
      "Total params: 263,526\n",
      "Trainable params: 263,526\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 1.12\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 2.15\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch:  0 | train loss: 2.8767 | test accuracy: 10.1718\n",
      "1.534865140914917\n",
      "OA =  10.171797924817145\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 8, 55, 11, 11]       --\n",
      "|    └─Conv3d: 2-1                            [-1, 8, 55, 11, 11]       656\n",
      "|    └─BatchNorm3d: 2-2                       [-1, 8, 55, 11, 11]       16\n",
      "|    └─ReLU: 2-3                              [-1, 8, 55, 11, 11]       --\n",
      "├─Sequential: 1-2                             [-1, 64, 11, 11]          --\n",
      "|    └─HetConv: 2-4                           [-1, 64, 11, 11]          --\n",
      "|    |    └─Conv2d: 3-1                       [-1, 64, 11, 11]          31,744\n",
      "|    |    └─Conv2d: 3-2                       [-1, 64, 11, 11]          28,224\n",
      "|    └─BatchNorm2d: 2-5                       [-1, 64, 11, 11]          128\n",
      "|    └─ReLU: 2-6                              [-1, 64, 11, 11]          --\n",
      "├─Sequential: 1-3                             [-1, 64, 11, 11]          --\n",
      "|    └─Conv2d: 2-7                            [-1, 64, 11, 11]          640\n",
      "|    └─BatchNorm2d: 2-8                       [-1, 64, 11, 11]          128\n",
      "|    └─GELU: 2-9                              [-1, 64, 11, 11]          --\n",
      "├─Dropout: 1-4                                [-1, 5, 64]               --\n",
      "├─TransformerEncoder: 1-5                     [-1, 64]                  --\n",
      "|    └─LayerNorm: 2-10                        [-1, 5, 64]               128\n",
      "|    |    └─Block: 3-3                        [-1, 5, 64]               100,736\n",
      "|    |    └─Block: 3-4                        [-1, 5, 64]               100,736\n",
      "├─Linear: 1-6                                 [-1, 6]                   390\n",
      "===============================================================================================\n",
      "Total params: 263,526\n",
      "Trainable params: 263,526\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 1.12\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 2.15\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MFT. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type HetConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransformerEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Block. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Mlp. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MCrossAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.2001 | test accuracy: 64.8240\n",
      "1.5208587646484375\n",
      "OA =  64.82394965130123\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 8, 55, 11, 11]       --\n",
      "|    └─Conv3d: 2-1                            [-1, 8, 55, 11, 11]       656\n",
      "|    └─BatchNorm3d: 2-2                       [-1, 8, 55, 11, 11]       16\n",
      "|    └─ReLU: 2-3                              [-1, 8, 55, 11, 11]       --\n",
      "├─Sequential: 1-2                             [-1, 64, 11, 11]          --\n",
      "|    └─HetConv: 2-4                           [-1, 64, 11, 11]          --\n",
      "|    |    └─Conv2d: 3-1                       [-1, 64, 11, 11]          31,744\n",
      "|    |    └─Conv2d: 3-2                       [-1, 64, 11, 11]          28,224\n",
      "|    └─BatchNorm2d: 2-5                       [-1, 64, 11, 11]          128\n",
      "|    └─ReLU: 2-6                              [-1, 64, 11, 11]          --\n",
      "├─Sequential: 1-3                             [-1, 64, 11, 11]          --\n",
      "|    └─Conv2d: 2-7                            [-1, 64, 11, 11]          640\n",
      "|    └─BatchNorm2d: 2-8                       [-1, 64, 11, 11]          128\n",
      "|    └─GELU: 2-9                              [-1, 64, 11, 11]          --\n",
      "├─Dropout: 1-4                                [-1, 5, 64]               --\n",
      "├─TransformerEncoder: 1-5                     [-1, 64]                  --\n",
      "|    └─LayerNorm: 2-10                        [-1, 5, 64]               128\n",
      "|    |    └─Block: 3-3                        [-1, 5, 64]               100,736\n",
      "|    |    └─Block: 3-4                        [-1, 5, 64]               100,736\n",
      "├─Linear: 1-6                                 [-1, 6]                   390\n",
      "===============================================================================================\n",
      "Total params: 263,526\n",
      "Trainable params: 263,526\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 1.12\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 2.15\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MFT. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type HetConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransformerEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Block. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Mlp. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MCrossAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.8173 | test accuracy: 13.2846\n",
      "1.5141539573669434\n",
      "OA =  13.284572206157511\n",
      "----------Trento Training Finished -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MFT. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type HetConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TransformerEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Block. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Mlp. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/users/jgecvision/.conda/envs/purb37/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MCrossAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "DATASETS_WITH_HSI_PARTS = ['Berlin', 'Augsburg']\n",
    "DATA2_List = ['SAR','DSM','MS']\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# All datasets = \"Houston\",\"Trento\",\"MUUFL\",\"HoustonMS\",\"AugsburgSAR\",\"AugsburgDSM\"\n",
    "datasetNames = [\"Trento\"]\n",
    "\n",
    "patchsize = 11\n",
    "batchsize = 64\n",
    "testSizeNumber = 500\n",
    "EPOCH = 1\n",
    "BandSize = 1\n",
    "LR = 5e-4\n",
    "FM = 16\n",
    "HSIOnly = False\n",
    "FileName = 'MFT'\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc\n",
    "\n",
    "def reports (xtest,xtest2,ytest,name,model):\n",
    "    pred_y = np.empty((len(ytest)), dtype=np.float32)\n",
    "    number = len(ytest) // testSizeNumber\n",
    "    for i in range(number):\n",
    "        temp = xtest[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "        temp = temp.cuda()\n",
    "        temp1 = xtest2[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "        temp1 = temp1.cuda()\n",
    "\n",
    "        temp2 = model(temp,temp1)\n",
    "        \n",
    "        temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "        pred_y[i * testSizeNumber:(i + 1) * testSizeNumber] = temp3.cpu()\n",
    "        del temp, temp2, temp3,temp1\n",
    "\n",
    "    if (i + 1) * testSizeNumber < len(ytest):\n",
    "        temp = xtest[(i + 1) * testSizeNumber:len(ytest), :, :]\n",
    "        temp = temp.cuda()\n",
    "        temp1 = xtest2[(i + 1) * testSizeNumber:len(ytest), :, :]\n",
    "        temp1 = temp1.cuda()\n",
    "\n",
    "        temp2 = model(temp,temp1)\n",
    "        temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "        pred_y[(i + 1) * testSizeNumber:len(ytest)] = temp3.cpu()\n",
    "        del temp, temp2, temp3,temp1\n",
    "\n",
    "    pred_y = torch.from_numpy(pred_y).long()\n",
    "    \n",
    "    if name == 'Houston':\n",
    "        target_names = ['Healthy grass', 'Stressed grass', 'Synthetic grass'\n",
    "                        ,'Trees', 'Soil', 'Water', \n",
    "                        'Residential', 'Commercial', 'Road', 'Highway',\n",
    "                        'Railway', 'Parking Lot 1', 'Parking Lot 2', 'Tennis Court',\n",
    "                        'Running Track']\n",
    "    elif name == 'Trento':\n",
    "        target_names = ['Apples','Buildings','Ground','Woods','Vineyard',\n",
    "                        'Roads']\n",
    "    elif name == 'MUUFL' or name == 'MUUFLS' or name == 'MUUFLSR':\n",
    "        target_names = ['Trees','Grass_Pure','Grass_Groundsurface','Dirt_And_Sand', 'Road_Materials','Water',\"Buildings'_Shadow\",\n",
    "                    'Buildings','Sidewalk','Yellow_Curb','ClothPanels']\n",
    "    elif name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'UP':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "\n",
    "#     classification = classification_report(ytest, pred_y, target_names=target_names)\n",
    "    oa = accuracy_score(ytest, pred_y)\n",
    "    confusion = confusion_matrix(ytest, pred_y)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(ytest, pred_y)\n",
    "\n",
    "    return confusion, oa*100, each_acc*100, aa*100, kappa*100\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "for BandSize in [1]:\n",
    "    for datasetName in datasetNames:\n",
    "            print(\"----------------------------------Training for \",datasetName,\" ---------------------------------------------\")\n",
    "            try:\n",
    "                os.makedirs(datasetName)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            data1Name = ''\n",
    "            data2Name = ''\n",
    "            if datasetName in [\"Houston\",\"Trento\",\"MUUFL\"]:\n",
    "                data1Name = datasetName\n",
    "                data2Name = \"LIDAR\"\n",
    "            else:\n",
    "                for dataName in DATA2_List:\n",
    "                    dataNameToCheck = re.compile(dataName)\n",
    "                    matchObj = dataNameToCheck.search(datasetName)\n",
    "                    if matchObj:\n",
    "                        data1Name = datasetName.replace(dataName,\"\")\n",
    "                        data2Name = dataName\n",
    "            \n",
    "            \n",
    "            \n",
    "            HSI = io.loadmat('./../'+data1Name+'11x11/HSI_Tr.mat')\n",
    "            TrainPatch = HSI['Data']\n",
    "            TrainPatch = TrainPatch.astype(np.float32)\n",
    "            NC = TrainPatch.shape[3] # NC is number of bands\n",
    "\n",
    "            LIDAR = io.loadmat('./../'+data1Name+'11x11/'+data2Name+'_Tr.mat')\n",
    "            TrainPatch2 = LIDAR['Data']\n",
    "            TrainPatch2 = TrainPatch2.astype(np.float32)\n",
    "            NCLIDAR = TrainPatch2.shape[3] # NC is number of bands\n",
    "\n",
    "            label = io.loadmat('./../'+data1Name+'11x11/TrLabel.mat')\n",
    "            TrLabel = label['Data']\n",
    "\n",
    "            # Test data\n",
    "            if data1Name in DATASETS_WITH_HSI_PARTS:\n",
    "                i = 2\n",
    "                basePath = \"./../\"+data1Name+'11x11/HSI_Te_Part'\n",
    "                TestPatch = io.loadmat(basePath + str(i - 1) + '.mat')['Data']\n",
    "                while True:\n",
    "                    my_file = Path(basePath + str(i) + '.mat')\n",
    "                    if my_file.exists():\n",
    "                        TestPatch = np.concatenate([TestPatch,io.loadmat(basePath + str(i) + '.mat')['Data']], axis = 0)\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        break\n",
    "            else:\n",
    "                HSI = io.loadmat('./../'+data1Name+'11x11/HSI_Te.mat')\n",
    "                TestPatch = HSI['Data']\n",
    "            TestPatch = TestPatch.astype(np.float32)\n",
    "\n",
    "            LIDAR = io.loadmat('./../'+data1Name+'11x11/'+data2Name+'_Te.mat')\n",
    "            TestPatch2 = LIDAR['Data']\n",
    "            TestPatch2 = TestPatch2.astype(np.float32)\n",
    "\n",
    "            label = io.loadmat('./../'+data1Name+'11x11/TeLabel.mat')\n",
    "            TsLabel = label['Data']\n",
    "\n",
    "\n",
    "            TrainPatch1 = torch.from_numpy(TrainPatch).to(torch.float32)\n",
    "            TrainPatch1 = TrainPatch1.permute(0,3,1,2)\n",
    "            TrainPatch1 = TrainPatch1.reshape(TrainPatch1.shape[0],TrainPatch1.shape[1],-1).to(torch.float32)\n",
    "            TrainPatch2 = torch.from_numpy(TrainPatch2).to(torch.float32)\n",
    "            TrainPatch2 = TrainPatch2.permute(0,3,1,2)\n",
    "            TrainPatch2 = TrainPatch2.reshape(TrainPatch2.shape[0],TrainPatch2.shape[1],-1).to(torch.float32)\n",
    "            TrainLabel1 = torch.from_numpy(TrLabel)-1\n",
    "            TrainLabel1 = TrainLabel1.long()\n",
    "            TrainLabel1 = TrainLabel1.reshape(-1)\n",
    "\n",
    "            TestPatch1 = torch.from_numpy(TestPatch).to(torch.float32)\n",
    "            TestPatch1 = TestPatch1.permute(0,3,1,2)\n",
    "            TestPatch1 = TestPatch1.reshape(TestPatch1.shape[0],TestPatch1.shape[1],-1).to(torch.float32)\n",
    "            TestPatch2 = torch.from_numpy(TestPatch2).to(torch.float32)\n",
    "            TestPatch2 = TestPatch2.permute(0,3,1,2)\n",
    "            TestPatch2 = TestPatch2.reshape(TestPatch2.shape[0],TestPatch2.shape[1],-1).to(torch.float32)\n",
    "            TestLabel1 = torch.from_numpy(TsLabel)-1\n",
    "            TestLabel1 = TestLabel1.long()\n",
    "            TestLabel1 = TestLabel1.reshape(-1)\n",
    "\n",
    "            Classes = len(np.unique(TrainLabel1))\n",
    "            dataset = dataf.TensorDataset(TrainPatch1,TrainPatch2, TrainLabel1)\n",
    "            if data1Name in ['Berlin']:\n",
    "                train_loader = dataf.DataLoader(dataset, batch_size=batchsize, shuffle=True, num_workers= 0)\n",
    "            else:\n",
    "                train_loader = dataf.DataLoader(dataset, batch_size=batchsize, shuffle=True, num_workers= 4)\n",
    "            print(\"HSI Train data shape = \", TrainPatch1.shape)\n",
    "            print(data2Name + \" Train data shape = \", TrainPatch2.shape)\n",
    "            print(\"Train label shape = \", TrainLabel1.shape)\n",
    "\n",
    "            print(\"HSI Test data shape = \", TestPatch1.shape)\n",
    "            print(data2Name + \" Test data shape = \", TestPatch2.shape)\n",
    "            print(\"Test label shape = \", TestLabel1.shape)\n",
    "\n",
    "            print(\"Number of Classes = \", Classes)\n",
    "            KAPPA = []\n",
    "            OA = []\n",
    "            AA = []\n",
    "            ELEMENT_ACC = np.zeros((3, Classes))\n",
    "\n",
    "            set_seed(42)\n",
    "            for iterNum in range(3):\n",
    "                model = MFT(FM, NC, NCLIDAR, Classes, HSIOnly).cuda()\n",
    "                summary(model, [(NC, patchsize**2),(NCLIDAR,patchsize**2)])\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=5e-3)\n",
    "                loss_func = nn.CrossEntropyLoss()  # the target label is not one-hotted\n",
    "                scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "                BestAcc = 0\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                start = time.time()\n",
    "                # train and test the designed model\n",
    "                for epoch in range(EPOCH):\n",
    "                    for step, (b_x1, b_x2, b_y) in enumerate(train_loader):\n",
    "\n",
    "                        # move train data to GPU\n",
    "                        b_x1 = b_x1.cuda()\n",
    "                        b_y = b_y.cuda()\n",
    "                        if HSIOnly:\n",
    "                            out1 = model(b_x1,  b_x2)\n",
    "                            loss = loss_func(out1, b_y)\n",
    "                        else:\n",
    "                            b_x2 = b_x2.cuda()\n",
    "                            out= model(b_x1, b_x2)\n",
    "                            loss = loss_func(out, b_y)\n",
    "\n",
    "                        optimizer.zero_grad()  # clear gradients for this training step\n",
    "                        loss.backward()  # backpropagation, compute gradients\n",
    "                        optimizer.step()  # apply gradients\n",
    "\n",
    "                        if step % 50 == 0:\n",
    "                            model.eval()\n",
    "                            pred_y = np.empty((len(TestLabel1)), dtype='float32')\n",
    "                            number = len(TestLabel1) // testSizeNumber\n",
    "                            for i in range(number):\n",
    "                                temp = TestPatch1[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "                                temp = temp.cuda()\n",
    "                                temp1 = TestPatch2[i * testSizeNumber:(i + 1) * testSizeNumber, :, :]\n",
    "                                temp1 = temp1.cuda()\n",
    "                                if HSIOnly:\n",
    "                                    temp2 = model(temp, temp1)\n",
    "                                    temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "                                    pred_y[i * testSizeNumber:(i + 1) * testSizeNumber] = temp3.cpu()\n",
    "                                    del temp, temp2, temp3\n",
    "                                else:\n",
    "                                    temp2 = model(temp, temp1)\n",
    "                                    temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "                                    pred_y[i * testSizeNumber:(i + 1) * testSizeNumber] = temp3.cpu()\n",
    "                                    del temp, temp1, temp2, temp3\n",
    "\n",
    "                            if (i + 1) * testSizeNumber < len(TestLabel1):\n",
    "                                temp = TestPatch1[(i + 1) * testSizeNumber:len(TestLabel1), :, :]\n",
    "                                temp = temp.cuda()\n",
    "                                temp1 = TestPatch2[(i + 1) * testSizeNumber:len(TestLabel1), :, :]\n",
    "                                temp1 = temp1.cuda()\n",
    "                                if HSIOnly:\n",
    "                                    temp2 = model(temp, temp1)\n",
    "                                    temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "                                    pred_y[(i + 1) * testSizeNumber:len(TestLabel1)] = temp3.cpu()\n",
    "                                    del temp, temp2, temp3\n",
    "                                else:\n",
    "                                    temp2 = model(temp, temp1)\n",
    "                                    temp3 = torch.max(temp2, 1)[1].squeeze()\n",
    "                                    pred_y[(i + 1) * testSizeNumber:len(TestLabel1)] = temp3.cpu()\n",
    "                                    del temp, temp1, temp2, temp3\n",
    "\n",
    "                            pred_y = torch.from_numpy(pred_y).long()\n",
    "                            accuracy = torch.sum(pred_y == TestLabel1).type(torch.FloatTensor) / TestLabel1.size(0)\n",
    "\n",
    "                            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.4f' % (accuracy*100))\n",
    "\n",
    "                            # save the parameters in network\n",
    "                            if accuracy > BestAcc:\n",
    "\n",
    "                                BestAcc = accuracy\n",
    "                                \n",
    "                                torch.save(model.state_dict(), datasetName+'/net_params_'+FileName+'.pkl')\n",
    "                                \n",
    "\n",
    "                            model.train()\n",
    "                    scheduler.step()\n",
    "                torch.cuda.synchronize()\n",
    "                end = time.time()\n",
    "                print(end - start)\n",
    "                Train_time = end - start\n",
    "\n",
    "                # load the saved parameters\n",
    "                \n",
    "                model.load_state_dict(torch.load(datasetName+'/net_params_'+FileName+'.pkl'))\n",
    "\n",
    "                model.eval()\n",
    "                confusion, oa, each_acc, aa, kappa = reports(TestPatch1,TestPatch2,TestLabel1,datasetName,model)\n",
    "                KAPPA.append(kappa)\n",
    "                OA.append(oa)\n",
    "                AA.append(aa)\n",
    "                ELEMENT_ACC[iterNum, :] = each_acc\n",
    "                torch.save(model, datasetName+'/best_model_'+FileName+'_BandSize'+str(BandSize)+'_Iter'+str(iterNum)+'.pt')\n",
    "\n",
    "#                 classification = str(classification)\n",
    "#                 confusion = str(confusion)\n",
    "#                 each_acc = str(each_acc)\n",
    "#                 oa= str(oa)\n",
    "#                 if not HSIOnly:\n",
    "#                     file_name = datasetName+\"/classification_report_TransFuTesting_BandSize\"+str(BandSize)+'_Iter'+str(iterNum)+\".txt\"\n",
    "#                 else:\n",
    "#                     file_name = datasetName+\"/classification_report_HSIOnly_TransFuTesting_BandSize\"+str(BandSize)+'_Iter'+str(iterNum)+\".txt\"\n",
    "\n",
    "#                 with open(file_name, 'w') as x_file:\n",
    "#                     x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('{}'.format(classification))\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('{}'.format(confusion))\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('\\n')\n",
    "#                     x_file.write('{}'.format(each_acc))\n",
    "                print(\"OA = \", oa)\n",
    "            print(\"----------\" + datasetName + \" Training Finished -----------\")\n",
    "            record.record_output(OA, AA, KAPPA, ELEMENT_ACC,'./' + datasetName +'/'+FileName+'_BandSize'+str(BandSize)+'_Report_' + datasetName +'.txt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3830f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T15:58:11.759334Z",
     "start_time": "2022-02-03T15:58:11.381646Z"
    }
   },
   "outputs": [],
   "source": [
    "#MFT WITH PIXEL TOKENIZATION\n",
    "\n",
    "from torch.nn import LayerNorm,Linear,Dropout,Softmax\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def INF(B,H,W):\n",
    "     return -torch.diag(torch.tensor(float(\"inf\")).cuda().repeat(H),0).unsqueeze(0).repeat(B*W,1,1)\n",
    "\n",
    "     \n",
    "class HetConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,padding = None, bias = None,p = 64, g = 64):\n",
    "        super(HetConv, self).__init__()\n",
    "        # Groupwise Convolution\n",
    "        self.gwc = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,groups=g,padding = kernel_size//3, stride = stride)\n",
    "        # Pointwise Convolution\n",
    "        self.pwc = nn.Conv2d(in_channels, out_channels, kernel_size=1,groups=p, stride = stride)\n",
    "    def forward(self, x):\n",
    "        return self.gwc(x) + self.pwc(x)   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0.1, proj_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.wq = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "        self.wk = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "        self.wv = nn.Linear(head_dim, dim , bias=qkv_bias)\n",
    "#         self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim * num_heads, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        q = self.wq(x[:, 0:1, ...].reshape(B, 1, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  # B1C -> B1H(C/H) -> BH1(C/H)\n",
    "        k = self.wk(x.reshape(B, N, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "        v = self.wv(x.reshape(B, N, self.num_heads, C // self.num_heads)).permute(0, 2, 1, 3)  # BNC -> BNH(C/H) -> BHN(C/H)\n",
    "        attn = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "#         attn = (q @ k.transpose(-2, -1)) * self.scale  # BH1(C/H) @ BH(C/H)N -> BH1N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "#         attn = self.attn_drop(attn)\n",
    "        x = torch.einsum('bhij,bhjd->bhid', attn, v).transpose(1, 2)\n",
    "#         x = (attn @ v).transpose(1, 2)\n",
    "        x = x.reshape(B, 1, C * self.num_heads)   # (BH1N @ BHN(C/H)) -> BH1(C/H) -> B1H(C/H) -> B1C\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.fc1 = Linear(dim, 512)\n",
    "        self.fc2 = Linear(512, dim)\n",
    "        self.act_fn = nn.GELU()\n",
    "        self.dropout = Dropout(0.1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
    "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Block, self).__init__()\n",
    "        self.hidden_size = dim\n",
    "        self.attention_norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.ffn_norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.ffn = Mlp(dim)\n",
    "#         self.attn = Attention(dim = 64)\n",
    "        self.attn = CrossAttention(dim = dim)\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        x = self.attention_norm(x)\n",
    "        x= self.attn(x)\n",
    "        x = x + h\n",
    "\n",
    "        h = x\n",
    "        x = self.ffn_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = x + h\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads= 8, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0.1, attn_drop=0.1,\n",
    "                 drop_path=0.1, act_layer=nn.GELU, norm_layer=nn.LayerNorm, has_mlp=False):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.encoder_norm = LayerNorm(dim, eps=1e-6)\n",
    "        for _ in range(2):\n",
    "            layer = Block(dim)\n",
    "            self.layer.append(copy.deepcopy(layer))\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer_block in self.layer:\n",
    "            x= layer_block(x)\n",
    "            \n",
    "        encoded = self.encoder_norm(x)\n",
    "       \n",
    "        \n",
    "\n",
    "        return encoded[:,0]\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, FM, NC, NCLidar, Classes, HSIOnly):\n",
    "        super(CNN, self).__init__()\n",
    "        self.HSIOnly = HSIOnly\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, (9, 3, 3), padding=(0,1,1), stride = 1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv6 = nn.Sequential(\n",
    "            HetConv(8 * (NC - 8), FM*4,\n",
    "                p = 1,\n",
    "                g = (FM*4)//4 if (8 * (NC - 8))%FM == 0 else (FM*4)//8,\n",
    "                   ),\n",
    "            nn.BatchNorm2d(FM*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.last_BandSize = NC//2//2//2\n",
    "        \n",
    "        self.lidarConv = nn.Sequential(\n",
    "                        nn.Conv2d(NCLidar,1,3,1,1),\n",
    "                        nn.BatchNorm2d(1),\n",
    "                        nn.GELU()\n",
    "                        )\n",
    "        self.ca = CrossAttentionBlock(FM*4)\n",
    "        self.out3 = nn.Linear(FM*4 , Classes)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(1, 4 + 1, FM*4))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        torch.nn.init.xavier_uniform_(self.out3.weight)\n",
    "        torch.nn.init.normal_(self.out3.bias, std=1e-6)\n",
    "        self.token_wA = nn.Parameter(torch.empty(1, 4, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wA)\n",
    "        self.token_wV = nn.Parameter(torch.empty(1, 64, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wV)\n",
    "        \n",
    "        self.token_wA_L = nn.Parameter(torch.empty(1, 1, 1),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wA_L)\n",
    "        self.token_wV_L = nn.Parameter(torch.empty(1, 1, 64),\n",
    "                                     requires_grad=True)  # Tokenization parameters\n",
    "        torch.nn.init.xavier_normal_(self.token_wV_L)\n",
    "                \n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = x1.reshape(x1.shape[0],-1,patchsize,patchsize)\n",
    "        x1 = x1.unsqueeze(1)\n",
    "        x2 = x2.reshape(x2.shape[0],-1,patchsize,patchsize)\n",
    "        x1 = self.conv5(x1)\n",
    "        x1 = x1.reshape(x1.shape[0],-1,patchsize,patchsize)\n",
    "        \n",
    "        x1 = self.conv6(x1)\n",
    "        x2 = self.lidarConv(x2)\n",
    "        x2 = x2.reshape(x2.shape[0],-1,patchsize**2)\n",
    "        x2 = x2.transpose(-1, -2)\n",
    "        wa_L = self.token_wA_L.expand(x1.shape[0],-1,-1)\n",
    "        A_L = torch.einsum('bij,bjk->bik', x2, wa_L)\n",
    "        A_L = rearrange(A_L, 'b h w -> b w h')  # Transpose\n",
    "        A_L = A_L.softmax(dim=-1)\n",
    "        wv_L = self.token_wV_L.expand(x2.shape[0],-1,-1)\n",
    "        VV_L = torch.einsum('bij,bjk->bik', x2, wv_L)\n",
    "        x2 = torch.einsum('bij,bjk->bik', A_L, VV_L)\n",
    "        x1 = x1.flatten(2)\n",
    "        \n",
    "        x1 = x1.transpose(-1, -2)\n",
    "        wa = self.token_wA.expand(x1.shape[0],-1,-1)\n",
    "        wa = rearrange(wa, 'b h w -> b w h')  # Transpose\n",
    "        A = torch.einsum('bij,bjk->bik', x1, wa)\n",
    "        A = rearrange(A, 'b h w -> b w h')  # Transpose\n",
    "        A = A.softmax(dim=-1)\n",
    "        wv = self.token_wV.expand(x1.shape[0],-1,-1)\n",
    "        VV = torch.einsum('bij,bjk->bik', x1, wv)\n",
    "        T = torch.einsum('bij,bjk->bik', A, VV)\n",
    "        x = torch.cat((x2, T), dim = 1) #[b,n+1,dim]\n",
    "        embeddings = x + self.position_embeddings\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        x = self.ca(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        out3 = self.out3(x)\n",
    "        return out3\n",
    "  \n",
    "\n",
    "\n",
    "batchsize = 64\n",
    "patchsize = 11\n",
    "model = (16, 144,1, 15, False)\n",
    "summary(model, [(144,121),(1,121)],device = 'cpu',depth = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d481d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:01:38.865956Z",
     "start_time": "2022-01-28T15:01:38.737981Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c9e17",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-28T15:03:25.784Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03730083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T11:36:28.634305Z",
     "start_time": "2022-01-29T11:36:28.598863Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a618a3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-29T11:37:35.691Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26407125db06bdd9abe40e82cf041582bb19887fa16dd38638e528b7039723e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
